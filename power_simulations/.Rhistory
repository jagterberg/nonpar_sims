Ipq <- diag(c(1,-1,-1),3,3)
pis <- c(.35,.35,.3)
assignmentvector1 <- rmultinom(n,1,pis)
Xtrue <- t(assignmentvector1) %*% nus_true1
P1 <- Xtrue %*%Ipq %*% t(Xtrue)
A <- generateAdjacencyMatrix(P1)
A1s1 <- A
A <- generateAdjacencyMatrix(P1)
A1s2 <- A
A <- generateAdjacencyMatrix(P1)
A2s1 <- A
A <- generateAdjacencyMatrix(P1)
A2s2 <- A
rm(A,assignmentvector1,B,Ipq,nus_true1,P1,Xtrie,n,nus,pis)
rm(Xtrue)
rm(generateAdjacencyMatrix())
rm(generateAdjacencyMatrix
)
diag(A1s1) <- rowSums(A1s1) / (nrow(A1s1)-1)
diag(A2s2) <- rowSums(A2s2) / (nrow(A2s2)-1)
diag(A1s2) <- rowSums(A1s2) / (nrow(A1s2)-1)
diag(A2s1) <- rowSums(A2s1) / (nrow(A2s1)-1)
A1s1_eigen <- eigen(A1s1, symmetric = TRUE,only.values = TRUE)
A2s2_eigen <- eigen(A2s2, symmetric = TRUE,only.values=TRUE)
A1s2_eigen <- eigen(A1s2, symmetric = TRUE,only.values = TRUE)
A2s1_eigen <- eigen(A2s1, symmetric = TRUE,only.values = TRUE)
dA1s1 <- sort(abs(A1s1_eigen$values),decreasing = TRUE,index.return=TRUE)
dA2s2 <- sort(abs(A2s2_eigen$values),decreasing = TRUE,index.return=TRUE)
dA2s2 <- sort(abs(A2s2_eigen$values),decreasing = TRUE,index.return=TRUE)
dA1s2 <- sort(abs(A1s2_eigen$values),decreasing = TRUE,index.return=TRUE)
d1 <- getElbows(dA1s1$x,2)
d2 <- getElbows(dA2s2$x,2)
d3 <- getElbows(dA2s2$x,2)
d4 <- getElbows(dA1s2$x,2)
d <- max(d1,d2,d3,d4)
d
A1s1_svd <- irlba(A1s1,d)
A1s2_svd <- irlba(A1s2,d)
A2s1_svd <- irlba(A2s1,d)
A2s2_svd <- irlba(A2s2,d)
Xhat_A1s1 <- A1s1_svd$u[,c(1:d)] %*% diag(A1s1_svd$d[c(1:d)])^(1/2)
Xhat_A1s2 <- A1s2_svd$u[,c(1:d)] %*% diag(A1s2_svd$d[c(1:d)])^(1/2)
Xhat_A2s1 <- A2s1_svd$u[,c(1:d)] %*% diag(A2s1_svd$d[c(1:d)])^(1/2)
Xhat_A2s2 <- A2s2_svd$u[,c(1:d)] %*% diag(A2s2_svd$d[c(1:d)])^(1/2)
phat <- sum(ifelse(A1s1_eigen$values[dA1$ix[c(1:d)]] > 0,1,0))
phat <- sum(ifelse(A1s1_eigen$values[dA1s1$ix[c(1:d)]] > 0,1,0))
qhat <- d - phat
pq <- c(phat,qhat)
names(pq) <- c("phat","qhat")
results <- list()
results[[1]] <- pq
results
rm(A1s1,A1s2,A2s1,A2s2)
i <- i+1
i <- 2
out <- match_support(Xhat_A1s1, Xhat_A1s2,  numReps=50)
pval <- nonpar.test(Xhat_A1s1  %*% out$Q ,Xhat_A1s2)
results[[i]] <- pval
names(results[[i]]) <- "A1s1 to A1s2"
results
rm(list = ls())
load("data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
A1s1 <- get.adjacency(glist[[1]])
if(!require(nonparGraphTesting)) {
install.packages("nonparGraphTesting_0.1.0.tar.gz", repos = NULL, type="source")
library(nonparGraphTesting)
}
if (!require(irlba)) {
install.packages("irlba")
library(irlba)
}
if(!require(igraph)) {
install.packages("igraph")
library(igraph)
}
if(!require(Rcpp)) {
install.packages("Rcpp")
library(Rcpp)
}
getElbows <- function(dat, n = 3, threshold = FALSE, plot = TRUE, main="") {
## Given a decreasingly sorted vector, return the given number of elbows
##
## Args:
##   dat: a input vector (e.g. a vector of standard deviations), or a input feature matrix.
##   n: the number of returned elbows.
##   threshold: either FALSE or a number. If threshold is a number, then all
##   the elements in d that are not larger than the threshold will be ignored.
##   plot: logical. When T, it depicts a scree plot with highlighted elbows.
##
## Return:
##   q: a vector of length n.
##
## Reference:
##   Zhu, Mu and Ghodsi, Ali (2006), "Automatic dimensionality selection from
##   the scree plot via the use of profile likelihood", Computational
##   Statistics & Data Analysis, Volume 51 Issue 2, pp 918-930, November, 2006.
#  if (is.unsorted(-d))
if (is.matrix(dat)) {
d <- sort(apply(dat,2,sd), decreasing=TRUE)
} else {
d <- sort(dat,decreasing=TRUE)
}
if (!is.logical(threshold))
d <- d[d > threshold]
p <- length(d)
if (p == 0)
stop(paste("d must have elements that are larger than the threshold ",
threshold), "!", sep="")
lq <- rep(0.0, p)                     # log likelihood, function of q
for (q in 1:p) {
mu1 <- mean(d[1:q])
mu2 <- mean(d[-(1:q)])              # = NaN when q = p
sigma2 <- (sum((d[1:q] - mu1)^2) + sum((d[-(1:q)] - mu2)^2)) /
(p - 1 - (q < p))
lq[q] <- sum( dnorm(  d[1:q ], mu1, sqrt(sigma2), log=TRUE) ) +
sum( dnorm(d[-(1:q)], mu2, sqrt(sigma2), log=TRUE) )
}
q <- which.max(lq)
if (n > 1 && q < (p-1)) {
q <- c(q, q + getElbows(d[(q+1):p], n-1, plot=FALSE))
}
if (plot==TRUE) {
if (is.matrix(dat)) {
sdv <- d # apply(dat,2,sd)
plot(sdv,type="b",xlab="dim",ylab="stdev",main=main)
points(q,sdv[q],col=2,pch=19)
} else {
plot(dat, type="b",main=main)
points(q,dat[q],col=2,pch=19)
}
}
return(q)
}
load("data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
A1s1 <- get.adjacency(glist[[1]])
A2s2 <- get.adjacency(glist[[2]])
load("data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
A1s1 <- get.adjacency(glist[[1]])
A2s1 <- get.adjacency(glist[[2]])
A1s2 <- get.adjacency(glist[[3]])
A2s2 <- get.adjacency(glist[[4]])
rm(glist)
diag(A1s1) <- rowSums(A1s1) / (nrow(A1s1)-1)
diag(A2s2) <- rowSums(A2s2) / (nrow(A2s2)-1)
diag(A1s2) <- rowSums(A1s2) / (nrow(A1s2)-1)
if(!require(nonparGraphTesting)) {
install.packages("nonparGraphTesting_0.1.0.tar.gz", repos = NULL, type="source")
library(nonparGraphTesting)
}
if (!require(irlba)) {
install.packages("irlba")
library(irlba)
}
if(!require(igraph)) {
install.packages("igraph")
library(igraph)
}
if(!require(Rcpp)) {
install.packages("Rcpp")
library(Rcpp)
}
getElbows <- function(dat, n = 3, threshold = FALSE, plot = TRUE, main="") {
## Given a decreasingly sorted vector, return the given number of elbows
##
## Args:
##   dat: a input vector (e.g. a vector of standard deviations), or a input feature matrix.
##   n: the number of returned elbows.
##   threshold: either FALSE or a number. If threshold is a number, then all
##   the elements in d that are not larger than the threshold will be ignored.
##   plot: logical. When T, it depicts a scree plot with highlighted elbows.
##
## Return:
##   q: a vector of length n.
##
## Reference:
##   Zhu, Mu and Ghodsi, Ali (2006), "Automatic dimensionality selection from
##   the scree plot via the use of profile likelihood", Computational
##   Statistics & Data Analysis, Volume 51 Issue 2, pp 918-930, November, 2006.
#  if (is.unsorted(-d))
if (is.matrix(dat)) {
d <- sort(apply(dat,2,sd), decreasing=TRUE)
} else {
d <- sort(dat,decreasing=TRUE)
}
if (!is.logical(threshold))
d <- d[d > threshold]
p <- length(d)
if (p == 0)
stop(paste("d must have elements that are larger than the threshold ",
threshold), "!", sep="")
lq <- rep(0.0, p)                     # log likelihood, function of q
for (q in 1:p) {
mu1 <- mean(d[1:q])
mu2 <- mean(d[-(1:q)])              # = NaN when q = p
sigma2 <- (sum((d[1:q] - mu1)^2) + sum((d[-(1:q)] - mu2)^2)) /
(p - 1 - (q < p))
lq[q] <- sum( dnorm(  d[1:q ], mu1, sqrt(sigma2), log=TRUE) ) +
sum( dnorm(d[-(1:q)], mu2, sqrt(sigma2), log=TRUE) )
}
q <- which.max(lq)
if (n > 1 && q < (p-1)) {
q <- c(q, q + getElbows(d[(q+1):p], n-1, plot=FALSE))
}
if (plot==TRUE) {
if (is.matrix(dat)) {
sdv <- d # apply(dat,2,sd)
plot(sdv,type="b",xlab="dim",ylab="stdev",main=main)
points(q,sdv[q],col=2,pch=19)
} else {
plot(dat, type="b",main=main)
points(q,dat[q],col=2,pch=19)
}
}
return(q)
}
load("data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
A1s1 <- get.adjacency(glist[[1]])
A2s1 <- get.adjacency(glist[[2]])
A1s2 <- get.adjacency(glist[[3]])
A2s2 <- get.adjacency(glist[[4]])
rm(glist)
diag(A1s1) <- rowSums(A1s1) / (nrow(A1s1)-1)
diag(A2s2) <- rowSums(A2s2) / (nrow(A2s2)-1)
diag(A1s2) <- rowSums(A1s2) / (nrow(A1s2)-1)
diag(A2s1) <- rowSums(A2s1) / (nrow(A2s1)-1)
dat <- list(A1s1,A2s1,A1s2,A2s2)
save(dat,file = "data/dat.RData")
rm(list = ls())
load("data/dat.RData")
rm(dat)
if(!require(nonparGraphTesting)) {
install.packages("nonparGraphTesting_0.1.0.tar.gz", repos = NULL, type="source")
library(nonparGraphTesting)
}
if (!require(irlba)) {
install.packages("irlba")
library(irlba)
}
if(!require(igraph)) {
install.packages("igraph")
library(igraph)
}
if(!require(Rcpp)) {
install.packages("Rcpp")
library(Rcpp)
}
getElbows <- function(dat, n = 3, threshold = FALSE, plot = TRUE, main="") {
## Given a decreasingly sorted vector, return the given number of elbows
##
## Args:
##   dat: a input vector (e.g. a vector of standard deviations), or a input feature matrix.
##   n: the number of returned elbows.
##   threshold: either FALSE or a number. If threshold is a number, then all
##   the elements in d that are not larger than the threshold will be ignored.
##   plot: logical. When T, it depicts a scree plot with highlighted elbows.
##
## Return:
##   q: a vector of length n.
##
## Reference:
##   Zhu, Mu and Ghodsi, Ali (2006), "Automatic dimensionality selection from
##   the scree plot via the use of profile likelihood", Computational
##   Statistics & Data Analysis, Volume 51 Issue 2, pp 918-930, November, 2006.
#  if (is.unsorted(-d))
if (is.matrix(dat)) {
d <- sort(apply(dat,2,sd), decreasing=TRUE)
} else {
d <- sort(dat,decreasing=TRUE)
}
if (!is.logical(threshold))
d <- d[d > threshold]
p <- length(d)
if (p == 0)
stop(paste("d must have elements that are larger than the threshold ",
threshold), "!", sep="")
lq <- rep(0.0, p)                     # log likelihood, function of q
for (q in 1:p) {
mu1 <- mean(d[1:q])
mu2 <- mean(d[-(1:q)])              # = NaN when q = p
sigma2 <- (sum((d[1:q] - mu1)^2) + sum((d[-(1:q)] - mu2)^2)) /
(p - 1 - (q < p))
lq[q] <- sum( dnorm(  d[1:q ], mu1, sqrt(sigma2), log=TRUE) ) +
sum( dnorm(d[-(1:q)], mu2, sqrt(sigma2), log=TRUE) )
}
q <- which.max(lq)
if (n > 1 && q < (p-1)) {
q <- c(q, q + getElbows(d[(q+1):p], n-1, plot=FALSE))
}
if (plot==TRUE) {
if (is.matrix(dat)) {
sdv <- d # apply(dat,2,sd)
plot(sdv,type="b",xlab="dim",ylab="stdev",main=main)
points(q,sdv[q],col=2,pch=19)
} else {
plot(dat, type="b",main=main)
points(q,dat[q],col=2,pch=19)
}
}
return(q)
}
load("data/dat.RData")
A1s1 <- dat[[1]]
A2s1 <- dat[[2]]
A1s2 <- dat[[3]]
A2s2 <- dat[[4]]
rm(dat)
diag(A1s1)
A1s1_eigen <- eigen(A1s1, symmetric = TRUE,only.values = TRUE)
A2s2_eigen <- eigen(A2s2, symmetric = TRUE,only.values=TRUE)
A1s2_eigen <- eigen(A1s2, symmetric = TRUE,only.values = TRUE)
A2s1_eigen <- eigen(A2s1, symmetric = TRUE,only.values = TRUE)
dA1s1 <- sort(abs(A1s1_eigen$values),decreasing = TRUE,index.return=TRUE)
dA2s2 <- sort(abs(A2s2_eigen$values),decreasing = TRUE,index.return=TRUE)
dA2s2 <- sort(abs(A2s2_eigen$values),decreasing = TRUE,index.return=TRUE)
dA1s2 <- sort(abs(A1s2_eigen$values),decreasing = TRUE,index.return=TRUE)
d1 <- getElbows(dA1s1$x,2)
d2 <- getElbows(dA2s2$x,2)
d3 <- getElbows(dA2s2$x,2)
d4 <- getElbows(dA1s2$x,2)
d <- max(d1,d2,d3,d4)
A1s1_svd <- irlba(A1s1,d)
A1s2_svd <- irlba(A1s2,d)
A2s1_svd <- irlba(A2s1,d)
A2s2_svd <- irlba(A2s2,d)
Xhat_A1s1 <- A1s1_svd$u[,c(1:d)] %*% diag(A1s1_svd$d[c(1:d)])^(1/2)
Xhat_A1s2 <- A1s2_svd$u[,c(1:d)] %*% diag(A1s2_svd$d[c(1:d)])^(1/2)
Xhat_A2s1 <- A2s1_svd$u[,c(1:d)] %*% diag(A2s1_svd$d[c(1:d)])^(1/2)
Xhat_A2s2 <- A2s2_svd$u[,c(1:d)] %*% diag(A2s2_svd$d[c(1:d)])^(1/2)
rm(A1s1,A1s2,A2s1,A2s2)
phat <- sum(ifelse(A1s1_eigen$values[dA1s1$ix[c(1:d)]] > 0,1,0))
qhat <- d - phat
pq <- c(phat,qhat)
names(pq) <- c("phat","qhat")
results <- list()
results[[1]] <- pq
print("testing A1s1 to A1s2")
i <- 2
out <- match_support(Xhat_A1s1, Xhat_A1s2,  numReps=50)
pval <- nonpar.test(Xhat_A1s1  %*% out$Q ,Xhat_A1s2)
pval <- nonpar.test(Xhat_A1s1 ,Xhat_A2s2)# %*% out$Q ,Xhat_A1s2)
pval
load("real_data_results.Rdata")
results
q()
results
?nonpar.test
library(nonparGraphTesting)
?nonpar.test
nonpar.test
run_perm_test
nonpar.test
ptr <- function(g)
{
if (class(g) != "igraph") {
if (!is.matrix(g)) stop("the input has to be either an igraph object or a matrix!")
else {
if (ncol(g)==2) g <- graph_from_edgelist(g)
else if (nrow(g)==ncol(g)) g <- graph_from_adjacency_matrix(g, weighted = TRUE)
else stop("the input matrix is not a graph format!")
}
}
if (is.weighted(g)) {
W <- E(g)$weight
} else { # no-op!
W <- rep(1,ecount(g))
}
E(g)$weight <- rank(W)*2 / (ecount(g)+1)
return(g)
}
load("data/dat.RData")
A1s1 <- ptr(dat[[1]])
class(dat[[1]])
library(igraph)
A1s1 <- ptr(dat[[1]])
class(dat[[1]])
load("../data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
load("data/TT-DSDS01216-glist114-raw-LCCTRUE.rda")
dat <- list(A1s1,A2s1,A1s2,A2s2)
glist[[1]]
dat <- list(glist[[1]],glist[[2]],glist[[3]],glist[[4]])
A1s1 <- ptr(dat[[1]])
A1s2 <- ptr(dat[[2]])
A2s1 <- ptr(dat[[3]])
A2s2 <- ptr(dat[[4]])
A1s1 <- get.adjacency(A1s1)
A2s1 <- get.adjacency(A2s1)
A1s2 <- get.adjacency(A1s2)
A2s2 <- get.adjacency(A2s2)
rm(dat)
diag(A1s1) <- rowSums(A1s1) / (nrow(A1s1)-1)
library(Matrix)
diag(A1s1) <- rowSums(A1s1) / (nrow(A1s1)-1)
diag(A2s2) <- rowSums(A2s2) / (nrow(A2s2)-1)
diag(A1s2) <- rowSums(A1s2) / (nrow(A1s2)-1)
diag(A2s1) <- rowSums(A2s1) / (nrow(A2s1)-1)
dat <- list(A1s1,A1s2,A2s1,A2s2)
save(dat,file = "data/dat.RData")
rm(list = ls())
results
load("C:/Users/joshu/Dropbox/Documents/Research/grdpg_nonpar/optimal_transport/nonpar_sims/real_data_results_6-17.Rdata")
library(nonparGraphTesting)
?kernel.stat
kernel.stat
results
results[[1]]
library(nonparGraphTesting)
kernel.stat
run_perm_test
kernel.stat
run_perm_test
rm(list = ls())
getwd()
setwd("./power_simulations")
getwd()
load("MC_results_power_2.Rdata")
vals
results <- matrix(0,9,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
results2 <- t(results)
rm(results)
results2[,"0"] <- sapply(vals$`0`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.05"] <- sapply(vals$`0`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.1"] <- sapply(vals$`0.1`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.15"] <- sapply(vals$`0.15`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.2"] <- sapply(vals$`0.2`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.25"] <- sapply(vals$`0.25`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.3"] <- sapply(vals$`0.3`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.35"] <- sapply(vals$`0.35`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.4"] <- sapply(vals$`0.4`,function(x){sum(ifelse(x > .95,1,0)) })
t(results2)
500 - t(results2)
load("MC_results_power_2.Rdata")
results <- matrix(0,9,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
results2 <- t(results)
rm(results)
results2[,"0"] <- sapply(vals$`0`,mean)
results2[,"0.05"] <- sapply(vals$`0`,mean)
results2[,"0.1"] <- sapply(vals$`0.1`,mean)
results2[,"0.15"] <- sapply(vals$`0.15`,mean)
results2[,"0.2"] <- sapply(vals$`0.2`,mean)
results2[,"0.25"] <- sapply(vals$`0.25`,mean)
results2[,"0.3"] <- sapply(vals$`0.3`,mean)
results2[,"0.35"] <- sapply(vals$`0.35`,mean)
results2[,"0.4"] <- sapply(vals$`0.4`,mean)
results2
vals2 <- vals
results <- matrix(0,9,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
results2 <- t(results)
results <- matrix(0,9,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
names(vals)
results <- matrix(0,8,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
results2 <- t(results)
rm(results)
results2[,"0"] <- sapply(vals$`0`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.05"] <- sapply(vals$`0`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.1"] <- sapply(vals$`0.1`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.15"] <- sapply(vals$`0.15`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.2"] <- sapply(vals$`0.2`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.25"] <- sapply(vals$`0.25`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.3"] <- sapply(vals$`0.3`,function(x){sum(ifelse(x > .95,1,0)) })
results2[,"0.35"] <- sapply(vals$`0.35`,function(x){sum(ifelse(x > .95,1,0)) })
t(results2)
results2[,"0"] <- sapply(vals$`0`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.05"] <- sapply(vals$`0`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.1"] <- sapply(vals$`0.1`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.15"] <- sapply(vals$`0.15`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.2"] <- sapply(vals$`0.2`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.25"] <- sapply(vals$`0.25`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.3"] <- sapply(vals$`0.3`,function(x){sum(ifelse(x < .05,1,0)) })
results2[,"0.35"] <- sapply(vals$`0.35`,function(x){sum(ifelse(x < .05,1,0)) })
t(results2)
library(ggplot2)
library(reshape2)
gg_dat <- as.data.frame(t(results2/100))
gg_dat$eps <- colnames(results2)
gg_dat <- melt(gg_dat)
gg_dat$n <- as.integer(as.character(gg_dat$variable))
gg_dat$variable <- NULL
g <- ggplot(data=gg_dat,aes(x = n, y = value))
g+  theme_bw() +
theme(plot.title = element_text(size = 10,hjust = 0.5))+
ylab("Estimated Power") +
ggtitle("Power Curve for Different Values of Epsilon") +
geom_line(aes(color = eps, group = eps),lwd=1,
position=position_jitter(w=0.02, h=.012)) +
geom_hline(yintercept = .05,linetype = "dashed")+
# scale_x_continuous(limits = c(50,550)) +
scale_y_continuous(limits = c(-0.02,1.02),breaks= c(0.00,0.05,0.25,0.5,.75,1.00))
results <- matrix(0,8,5)
colnames(results) <- c(100,200,300,400,500)
rownames(results) <- names(vals)
results2 <- t(results)
rm(results)
results2[,"0"] <- sapply(vals$`0`,mean)
results2[,"0.05"] <- sapply(vals$`0`,mean)
results2[,"0.1"] <- sapply(vals$`0.1`,mean)
results2[,"0.15"] <- sapply(vals$`0.15`,mean)
results2[,"0.2"] <- sapply(vals$`0.2`,mean)
results2[,"0.25"] <- sapply(vals$`0.25`,mean)
results2[,"0.3"] <- sapply(vals$`0.3`,mean)
results2[,"0.35"] <- sapply(vals$`0.35`,mean)
results2
?nonparGraphTesting
